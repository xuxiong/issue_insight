#!/usr/bin/env python3
"""
æµ‹è¯•æ‰§è¡Œè„šæœ¬ - å¸¦è¶…æ—¶æ§åˆ¶çš„æµ‹è¯•è¿è¡Œå™¨

åŠŸèƒ½ç‰¹æ€§ï¼š
- æ‰¾åˆ°æ‰€æœ‰æµ‹è¯•æ–‡ä»¶ï¼ˆtests/**/*.pyï¼Œæ’é™¤ __init__.py å’Œ conftest.pyï¼‰
- ä¸ºæ¯ä¸ªæµ‹è¯•æ–‡ä»¶å•ç‹¬æ‰§è¡Œ uv run pytestï¼Œæ”¯æŒå‘½ä»¤è¡Œ --timeout å‚æ•°æ§åˆ¶è¶…æ—¶ï¼ˆé»˜è®¤10ç§’ï¼‰
- æ•è·æ¯ä¸ªæµ‹è¯•æ–‡ä»¶çš„æ‰§è¡Œç»“æœã€å¤±è´¥æ¯”ä¾‹å’Œå…·ä½“å¤±è´¥æ–¹æ³•
- è®°å½•æ‰§è¡Œæ—¶é—´å’Œè¯¦ç»†è¾“å‡º
- ä½¿ç”¨ rich åº“æä¾›ç¾è§‚çš„ç»ˆç«¯è¾“å‡º
"""

import argparse
import glob
import re
import subprocess
import sys
import time
from datetime import datetime
from enum import Enum
from pathlib import Path
from typing import List, Tuple, Dict, Any

from rich.console import Console
from rich.panel import Panel
from rich.table import Table
from rich.text import Text
from rich.columns import Columns


class TestResult(Enum):
    """æµ‹è¯•ç»“æœæšä¸¾"""
    PASSED = "âœ… é€šè¿‡"
    FAILED = "âŒ å¤±è´¥"
    TIMEOUT = "â±ï¸ è¶…æ—¶"
    ERROR = "ğŸ”¥ é”™è¯¯"


class TestExecutionResult:
    """å•ä¸ªæµ‹è¯•æ–‡ä»¶æ‰§è¡Œç»“æœ"""

    def __init__(self, file_path: Path):
        self.file_path = file_path
        self.result: TestResult = TestResult.ERROR
        self.execution_time: float = 0.0
        self.stdout: str = ""
        self.stderr: str = ""
        self.error_message: str = ""
        self.total_tests: int = 0
        self.failed_tests: int = 0
        self.failure_rate: float = 0.0
        self.failed_methods: List[str] = []

    def set_result(self, result: TestResult, execution_time: float = 0.0,
                   stdout: str = "", stderr: str = ""):
        """è®¾ç½®æµ‹è¯•ç»“æœ"""
        self.result = result
        self.execution_time = execution_time
        self.stdout = stdout
        self.stderr = stderr

        # è§£æpytestè¾“å‡ºï¼Œæå–å¤±è´¥ä¿¡æ¯
        self._parse_pytest_output(stdout, stderr)

    def _parse_pytest_output(self, stdout: str, stderr: str):
        """è§£æpytestè¾“å‡ºï¼Œæå–æµ‹è¯•ç»Ÿè®¡å’Œå¤±è´¥æ–¹æ³•ä¿¡æ¯"""
        # åˆå¹¶stdoutå’Œstderrè¿›è¡Œè§£æ
        full_output = stdout + stderr

        # åŒ¹é…å¤šç§pytestç»Ÿè®¡ä¿¡æ¯æ ¼å¼
        self.total_tests = 0
        self.failed_tests = 0
        self.failed_methods = []

        # é¦–å…ˆå°è¯•åŒ¹é…æ€»ç»“è¡Œï¼Œå¦‚ "4 failed, 31 passed in 0.18s"
        summary_pattern = r'(\d+)\s*failed.*?(\d+)\s*passed.*?\d+\.\d+s'
        summary_match = re.search(summary_pattern, full_output, re.IGNORECASE)
        if summary_match:
            failed, passed = map(int, summary_match.groups())
            self.failed_tests = failed
            self.total_tests = failed + passed

        # å¦‚æœæ²¡æ‰¾åˆ°æ€»ç»“è¡Œï¼Œå°è¯•åŒ¹é… "collected X items"
        if self.total_tests == 0:
            collected_pattern = r'collected\s+(\d+)'
            collected_match = re.search(collected_pattern, full_output, re.IGNORECASE)
            if collected_match:
                self.total_tests = int(collected_match.group(1))

        # å¦‚æœè¿˜æ˜¯æ²¡æ‰¾åˆ°æ€»æµ‹è¯•æ•°ï¼Œå°è¯•åŒ¹é…åªæœ‰å¤±è´¥çš„æ€»ç»“è¡Œï¼Œå¦‚ "11 failed in 0.20s"
        if self.total_tests == 0:
            failed_only_pattern = r'(\d+)\s*failed[^,]*in'
            failed_match = re.search(failed_only_pattern, full_output, re.IGNORECASE)
            if failed_match:
                self.failed_tests = int(failed_match.group(1))
                # å½“åŒ¹é… "N failed in TIME" ä¸”æ— passedæ—¶ï¼Œæ„å‘³ç€ N = æ€»æµ‹è¯•æ•°
                self.total_tests = self.failed_tests

        # æœ€åå°è¯•å¤„ç†ç‰¹æ®Šæƒ…å†µï¼šæ‰¾åˆ°å¤±è´¥æµ‹è¯•æ•°é‡ä½†æ²¡æ‰¾åˆ°æ€»æ•°
        if self.failed_tests > 0 and self.total_tests < self.failed_tests:
            self.total_tests = self.failed_tests

        # è®¡ç®—å¤±è´¥æ¯”ä¾‹
        if self.total_tests > 0:
            self.failure_rate = (self.failed_tests / self.total_tests * 100)
        else:
            # å¦‚æœæ²¡æœ‰æ”¶é›†åˆ°æµ‹è¯•æ•°é‡ä½†æœ‰å¤±è´¥ï¼Œæ ¹æ®æµ‹è¯•ç»“æœè®¾ç½®
            if self.result == TestResult.PASSED:
                self.failure_rate = 0.0
                self.total_tests = 1  # è‡³å°‘æœ‰1ä¸ªæµ‹è¯•
                self.failed_tests = 0
            elif self.result in [TestResult.FAILED, TestResult.TIMEOUT, TestResult.ERROR]:
                self.failure_rate = 100.0
                self.total_tests = 1  # è‡³å°‘æœ‰1ä¸ªæµ‹è¯•
                self.failed_tests = 1

        # åŒ¹é…å¤±è´¥çš„æµ‹è¯•æ–¹æ³•
        # pytestè¾“å‡ºæ ¼å¼å¦‚ï¼š
        # FAILED tests/unit/test_errors.py::TestAPIError::test_api_error_with_retry_info
        failed_method_pattern = r'^FAILED\s+(.*?)(?:\s|$)(?!.*\.\.\.)'
        failed_matches = re.findall(failed_method_pattern, full_output, re.MULTILINE)

        self.failed_methods = []
        for test_path in failed_matches:
            # æå–æ–¹æ³•åï¼Œæ ¼å¼é€šå¸¸æ˜¯ "tests/unit/test_errors.py::TestAPIError::test_api_error_with_retry_info"
            method_name = test_path.strip()
            if '::' in method_name:
                parts = method_name.split('::')
                if len(parts) >= 3:
                    # ä¿ç•™ç±»åå’Œæ–¹æ³•å: TestAPIError::test_api_error_with_retry_info
                    method_name = f"{parts[-2]}::{parts[-1]}"
                else:
                    # åªæœ‰æ–‡ä»¶å’Œæ–¹æ³•: test_file.py::function_name
                    method_name = parts[-1]
            else:
                # å¦‚æœæ²¡æœ‰::ï¼Œå¯èƒ½æ˜¯æ–‡ä»¶å
                method_name = Path(method_name).name

            # æ¸…ç†æ–¹æ³•åï¼Œé¿å…åŒ…å«å¤šä½™çš„å­—ç¬¦
            method_name = method_name.replace(' -', '').strip()
            if method_name and len(method_name) < 200 and method_name not in self.failed_methods:
                self.failed_methods.append(method_name)

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å…·ä½“çš„FAILEDè¡Œï¼Œå°è¯•ä»è¾“å‡ºä¸­è§£æå…¶ä»–å¤±è´¥ä¿¡æ¯
        # å¯¹äºä¸€äº›pytestè¾“å‡ºæ ¼å¼ï¼Œæˆ‘ä»¬å¯èƒ½éœ€è¦ä»å…¶ä»–åœ°æ–¹æå–æ–¹æ³•ä¿¡æ¯
        if not self.failed_methods and self.failed_tests > 0:
            # å°è¯•åŒ¹é… = FAILURES = éƒ¨åˆ†çš„æ–¹æ³•å
            failure_section_pattern = r'= FAILURES =\s*$'
            failure_start = re.search(failure_section_pattern, full_output, re.MULTILINE)
            if failure_start:
                # ä»FAILURESéƒ¨åˆ†å¼€å§‹æŸ¥æ‰¾æ–¹æ³•å
                failure_part = full_output[failure_start.end():]
                method_pattern = r'_+(\w+)::_+(\w+)\s*\)?'
                method_matches = re.findall(method_pattern, failure_part)
                if method_matches:
                    for class_name, method_name in method_matches:
                        clean_method = f"{class_name}::{method_name}"
                        if clean_method not in self.failed_methods:
                            self.failed_methods.append(clean_method)

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å…·ä½“çš„æ–¹æ³•åï¼Œä½†æœ‰å¤±è´¥ç»Ÿè®¡ï¼Œæ·»åŠ é€šç”¨çš„å¤±è´¥ä¿¡æ¯
        if not self.failed_methods and self.failed_tests > 0:
            self.failed_methods = [f"{self.failed_tests} ä¸ªæµ‹è¯•å¤±è´¥"]


class TestRunner:
    """æµ‹è¯•æ‰§è¡Œå™¨"""

    def __init__(self, timeout_seconds: int = 10):
        self.console = Console()
        self.timeout_seconds = timeout_seconds
        self.test_pattern = "tests/**/*.py"
        self.exclude_patterns = ["**/test_*.py", "**/*_test.py"]

    def find_test_files(self) -> List[Path]:
        """æ‰¾åˆ°æ‰€æœ‰æµ‹è¯•æ–‡ä»¶"""
        # ä½¿ç”¨ glob æ‰¾åˆ°æ‰€æœ‰æµ‹è¯•æ–‡ä»¶
        test_files = glob.glob(self.test_pattern, recursive=True)

        # è½¬æ¢ä¸º Path å¯¹è±¡å¹¶å»é‡
        test_paths = sorted(set(Path(f) for f in test_files))

        # æ’é™¤ __init__.py å’Œ conftest.py
        filtered_paths = []
        for path in test_paths:
            if path.name not in ["__init__.py", "conftest.py"]:
                filtered_paths.append(path)

        return filtered_paths

    def run_single_test(self, test_file: Path) -> TestExecutionResult:
        """è¿è¡Œå•ä¸ªæµ‹è¯•æ–‡ä»¶"""
        result = TestExecutionResult(test_file)

        start_time = time.time()
        try:
            # ä½¿ç”¨ subprocess.run æ‰§è¡Œ uv run pytestï¼Œä¸èƒ½ä½¿ç”¨ --timeout å‚æ•°ï¼Œé¿å…å†²çª
            cmd = ["uv", "run", "pytest", str(test_file)]

            self.console.print(f"\n[blue]æ‰§è¡Œæµ‹è¯•æ–‡ä»¶:[/blue] {test_file}")
            self.console.print(f"[dim]å‘½ä»¤: {' '.join(cmd)} (è¶…æ—¶: {self.timeout_seconds}s)[/dim]")

            # æ‰§è¡Œå‘½ä»¤ï¼Œè®¾ç½®è¶…æ—¶æ—¶é—´
            process = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=self.timeout_seconds  # ä¸¥æ ¼é™åˆ¶åœ¨é»˜è®¤10ç§’å†…ï¼ˆå¯é…ï¼‰
            )

            execution_time = time.time() - start_time

            # åˆ†æè¿”å›ç å’Œè¾“å‡º
            if process.returncode == 0:
                result.set_result(TestResult.PASSED, execution_time,
                                process.stdout, process.stderr)
            else:
                # æ£€æŸ¥ stderr æ˜¯å¦åŒ…å« pytest-timeout ç›¸å…³çš„ä¿¡æ¯
                stderr_upper = process.stderr.upper()
                if ("TIMEOUT" in stderr_upper or "INTERRUPTED" in stderr_upper or
                    execution_time >= self.timeout_seconds):
                    result.set_result(TestResult.TIMEOUT, execution_time,
                                    process.stdout, process.stderr)
                else:
                    result.set_result(TestResult.FAILED, execution_time,
                                    process.stdout, process.stderr)

        except subprocess.TimeoutExpired:
            execution_time = time.time() - start_time
            result.set_result(TestResult.TIMEOUT, execution_time)
            result.error_message = f"æµ‹è¯•æ‰§è¡Œè¶…è¿‡ {self.timeout_seconds} ç§’"
        except FileNotFoundError:
            result.error_message = f"æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {test_file}"
        except Exception as e:
            result.error_message = f"æ‰§è¡Œæµ‹è¯•æ—¶å‘ç”Ÿé”™è¯¯: {e}"

        return result

    def group_tests_by_directory(self, test_files: List[Path]) -> Dict[str, List[Path]]:
        """æŒ‰ç›®å½•åˆ†ç»„æµ‹è¯•æ–‡ä»¶"""
        groups = {
            "unit": [],
            "integration": [],
            "contract": []
        }

        for file_path in test_files:
            if "unit" in str(file_path):
                groups["unit"].append(file_path)
            elif "integration" in str(file_path):
                groups["integration"].append(file_path)
            elif "contract" in str(file_path):
                groups["contract"].append(file_path)

        return groups

    def display_results(self, results: List[TestExecutionResult]):
        """æ˜¾ç¤ºæµ‹è¯•ç»“æœ"""
        # åˆ›å»ºç»Ÿè®¡è¡¨
        table = Table(title="æµ‹è¯•æ‰§è¡Œç»“æœæ±‡æ€»")
        table.add_column("æµ‹è¯•æ–‡ä»¶", style="cyan", no_wrap=True)
        table.add_column("çŠ¶æ€", style="bold")
        table.add_column("æ‰§è¡Œæ—¶é—´", style="yellow", justify="right")
        table.add_column("å¤±è´¥æ¯”ä¾‹", style="red", justify="right")

        # ç»Ÿè®¡æ•°æ®
        total_tests = len(results)
        passed = sum(1 for r in results if r.result == TestResult.PASSED)
        failed = sum(1 for r in results if r.result == TestResult.FAILED)
        timeout = sum(1 for r in results if r.result == TestResult.TIMEOUT)
        success_rate = (passed / total_tests * 100) if total_tests > 0 else 0

        # æ·»åŠ ç»“æœåˆ°è¡¨
        for result in results:
            status_color = {
                TestResult.PASSED: "green",
                TestResult.FAILED: "red",
                TestResult.TIMEOUT: "orange1",
                TestResult.ERROR: "red"
            }.get(result.result, "white")

            # æ˜¾ç¤ºå¤±è´¥æ¯”ä¾‹
            failure_rate_display = "N/A"
            if result.total_tests > 0:
                failure_rate_display = f"{result.failure_rate:.1f}%"
            elif result.result in [TestResult.FAILED, TestResult.TIMEOUT, TestResult.ERROR]:
                failure_rate_display = "100.0%"

            table.add_row(
                str(result.file_path),
                f"[{status_color}]{result.result.value}[/{status_color}]",
                f"{result.execution_time:.2f}s",
                failure_rate_display
            )

        self.console.print(table)

        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        stats_text = f"""
æ€»æµ‹è¯•æ–‡ä»¶æ•°: {total_tests}
âœ… é€šè¿‡: {passed}
âŒ å¤±è´¥: {failed}
â±ï¸  è¶…æ—¶: {timeout}
ğŸ“Š é€šè¿‡ç‡: {success_rate:.1f}%
        """.strip()

        # æ ¹æ®ç»“æœæ˜¾ç¤ºæ€»ä½“ç»“è®º
        if passed == total_tests:
            conclusion = "ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼"
            conclusion_color = "green"
        elif timeout > 0:
            conclusion = f"âš ï¸  å­˜åœ¨è¶…æ—¶é—®é¢˜ ({timeout} ä¸ªæ–‡ä»¶è¶…æ—¶)"
            conclusion_color = "orange1"
        else:
            conclusion = f"âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ ({failed} ä¸ªæ–‡ä»¶å¤±è´¥)"
            conclusion_color = "red"

        self.console.print(Panel.fit(
            f"[bold {conclusion_color}]{conclusion}[/bold {conclusion_color}]\n\n{stats_text}",
            title="æ€»ä½“ç»“è®º"
        ))

    def display_failed_methods_details(self, results: List[TestExecutionResult]):
        """æ˜¾ç¤ºå¤±è´¥æ–¹æ³•çš„è¯¦ç»†ä¿¡æ¯"""
        failed_results = [r for r in results if r.failed_methods]

        if not failed_results:
            return

        self.console.print(f"\n\n[red]ğŸ” å¤±è´¥æ–¹æ³•è¯¦æƒ…:[/red]")

        for result in failed_results:
            self.console.print(f"\n[bold cyan]{result.file_path}[/bold cyan] - å¤±è´¥äº† {result.failed_tests}/{result.total_tests} ä¸ªæµ‹è¯• ({result.failure_rate:.1f}%)")

            for method in result.failed_methods:
                self.console.print(f"  âŒ {method}")

    def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        self.console.print(Panel.fit(
            "[bold blue]ğŸš€ å¼€å§‹æµ‹è¯•æ‰§è¡Œ[/bold blue]\n\n"
            f"ğŸ“ æµ‹è¯•æ¨¡å¼: {self.test_pattern}\n"
            f"â±ï¸  è¶…æ—¶è®¾ç½®: {self.timeout_seconds} ç§’\n"
            f"ğŸ• æ‰§è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            title="æµ‹è¯•æ‰§è¡Œé…ç½®"
        ))

        # æ‰¾åˆ°æ‰€æœ‰æµ‹è¯•æ–‡ä»¶
        test_files = self.find_test_files()

        if not test_files:
            self.console.print("[red]âŒ æœªæ‰¾åˆ°ä»»ä½•æµ‹è¯•æ–‡ä»¶[/red]")
            return

        # æŒ‰ç›®å½•åˆ†ç»„æ˜¾ç¤º
        grouped_tests = self.group_tests_by_directory(test_files)
        self.console.print("\n[blue]ğŸ“‹ å‘ç°çš„æµ‹è¯•æ–‡ä»¶:[/blue]")

        for group_name, files in grouped_tests.items():
            if files:
                self.console.print(f"\n[bold cyan]{group_name.upper()}[/bold cyan]:")
                for file_path in files:
                    self.console.print(f"  â€¢ {file_path}")

        # é€ä¸ªæ‰§è¡Œæµ‹è¯•
        results = []
        self.console.print(f"\n[blue]âš¡ å¼€å§‹é€ä¸ªæ‰§è¡Œæµ‹è¯• ({len(test_files)} ä¸ªæ–‡ä»¶)...[/blue]")

        for test_file in test_files:
            result = self.run_single_test(test_file)
            results.append(result)

            # æ˜¾ç¤ºç®€å•ç»“æœ
            status_color = {
                TestResult.PASSED: "green",
                TestResult.FAILED: "red",
                TestResult.TIMEOUT: "orange1",
                TestResult.ERROR: "red"
            }.get(result.result, "white")

            self.console.print(f"  {result.result.value} {result.file_path.name} "
                             f"({result.execution_time:.2f}s)")

        # æ˜¾ç¤ºè¯¦ç»†ç»“æœ
        self.console.print("\n")
        self.display_results(results)
        self.display_failed_methods_details(results)


def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description="æµ‹è¯•æ‰§è¡Œè„šæœ¬ - å¸¦è¶…æ—¶æ§åˆ¶çš„æµ‹è¯•è¿è¡Œå™¨",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  python run_tests_with_timeout.py                 # ä½¿ç”¨é»˜è®¤è¶…æ—¶10ç§’
  python run_tests_with_timeout.py --timeout 30    # è®¾ç½®30ç§’è¶…æ—¶
  python run_tests_with_timeout.py --timeout 5     # è®¾ç½®5ç§’è¶…æ—¶
        """.strip()
    )

    parser.add_argument(
        '--timeout',
        type=int,
        default=5,
        metavar='SECONDS',
        help='å•ä¸ªæµ‹è¯•æ–‡ä»¶æ‰§è¡Œçš„è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤5ç§’'
    )

    return parser.parse_args()


def main():
    """ä¸»å‡½æ•°"""
    args = parse_arguments()
    runner = TestRunner(timeout_seconds=args.timeout)
    runner.run_all_tests()


if __name__ == "__main__":
    main()
